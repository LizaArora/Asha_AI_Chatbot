
import os
import openai
import logging
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Set up logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Load Groq API configuration from .env
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_URL = os.getenv("GROQ_URL")

# Check if environment variables are loaded successfully
if not GROQ_API_KEY or not GROQ_URL:
    logger.error("GROQ API key or URL is missing in .env file.")
else:
    logger.info("GROQ API key and URL loaded successfully from .env")

# Configure OpenAI to use Groq endpoint
openai.api_key = GROQ_API_KEY
openai.api_base = GROQ_URL

# Use Groq's free model (llama3-8b-8192)
MODEL_NAME = "llama3-8b-8192"

def ask_gpt(question: str, chunks: list[str]) -> str:
    """
    Ask the Groq model a question based on the provided context (chunks).
    The model will generate an answer using the context and the question.

    Args:
        question (str): The question asked by the user.
        chunks (list[str]): The context (text chunks) based on which the question is answered.

    Returns:
        str: The answer generated by the model, or an error message if an exception occurs.
    """
    context = "\n\n".join(chunks)
    prompt = f"""Answer the question based on the context below:

Context:
{context}

Question: {question}"""
    
    # Log the prompt for debugging purposes (excluding sensitive information)
    logger.debug(f"Generated prompt: {prompt[:200]}...")  # Only log the first 200 characters for brevity

    try:
        # Request the Groq model to generate a response
        logger.info("Sending request to Groq model for question: %s", question)
        response = openai.ChatCompletion.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7
        )
        
        answer = response.choices[0].message["content"]
        logger.info("Received response from Groq model.")
        return answer
    
    except Exception as e:
        # Log the error if the request fails
        logger.error(f"Error generating response from Groq model: {e}")
        return f"Error generating response: {e}"
