import logging
from fastapi import FastAPI, Query
from fastapi.responses import JSONResponse

# Import from scraper logic
from scraper_app.scraping import scrape_url
from preprocessor.pipeline import process_and_store

# Import from chatbot logic
from chatbot_app.embedder import embed_text
from chatbot_app.vector_search import find_relevant_chunks
from chatbot_app.prompt import ask_gpt

# Set up logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

app = FastAPI()

@app.get("/scrape")
async def scrape_endpoint(url: str):
    """
    Endpoint to scrape the URL, process and store the content.
    It returns the cleaned text, title, and URL.

    Args:
        url (str): The URL to scrape.

    Returns:
        JSONResponse: Response with scraped data or error message.
    """
    logger.info(f"Scraping started for URL: {url}")
    try:
        # Step 1: Scrape content from the URL
        result = await scrape_url(url)
        logger.info(f"Scraping completed for URL: {url}")

        # Step 2: Preprocess the scraped content (clean → chunk → embed → store)
        logger.info(f"Processing and storing content for URL: {url}")
        process_and_store(url, result["title"], result["text"])
        logger.info(f"Processing and storage completed for URL: {url}")

        # Return response with scraped and processed content
        return JSONResponse(content={
            "content": result["text"],
            "title": result["title"],
            "url": url,
            "cleaned_text": result["text"],
            "message": "Scraping and preprocessing completed."
        })

    except Exception as e:
        logger.error(f"Error during scraping and processing for URL: {url} - {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.get("/ask")
async def ask_question(q: str = Query(..., description="User question")):
    """
    Endpoint to ask a question based on the scraped content. 
    The question is answered using relevant chunks from the database.

    Args:
        q (str): The user's question.

    Returns:
        JSONResponse: The answer generated by the model or an error message.
    """
    logger.info(f"Question received: {q}")
    try:
        # Embed the user question
        embedding = embed_text(q)
        logger.info(f"Question embedded successfully for: {q}")

        # Retrieve top chunks from Neo4j based on the embedded question
        chunks = find_relevant_chunks(embedding)
        logger.info(f"Retrieved {len(chunks)} relevant chunks for the question.")

        # Generate the answer based on the chunks and question
        answer = ask_gpt(q, chunks)
        logger.info(f"Answer generated successfully for the question: {q}")

        # Return the generated answer
        return {"answer": answer}

    except Exception as e:
        logger.error(f"Error during question processing: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})
