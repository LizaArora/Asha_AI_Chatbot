# Asha_AI_Chatbot
# ğŸ“˜ Web Scraper & AI-Powered Q&A API

A robust FastAPI-based microservice that scrapes web content, preprocesses and stores it in **Neo4j**, and delivers AI-powered answers to user queries. This API integrates modern scraping, NLP-based preprocessing, vector search using Neo4j, and GPT-driven natural language response generation.

---

## ğŸ“Œ Key Features

- **ğŸ” Web Scraping**: Asynchronously scrapes and extracts content and metadata from any valid URL.
- **ğŸ§¼ Text Preprocessing**: Cleans raw HTML, segments content into chunks, and embeds it for semantic search.
- **ğŸ§  Vector Storage with Neo4j**: Stores vector embeddings in a Neo4j graph database for efficient similarity search.
- **ğŸ” Semantic Search**: Embeds user queries and retrieves the most relevant content chunks using cosine similarity.
- **ğŸ’¬ GPT-Powered Answers**: Generates intelligent, context-aware answers using retrieved data and an LLM.
- **ğŸ§© Modular Design**: Clear separation between scraping, processing, embedding, vector search, and response generation.


---
## âš™ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/LizaArora/Asha_AI_Chatbot.git
cd Asha_AI_Chatbot

### 2. Install Dependencies
pip install -r requirements.txt

### 3. You are ready to code

HAVE A NICE CODING

ğŸš€ Running the Application
uvicorn main:app --host 0.0.0.0 --port 8000 --reload

ğŸ“’ Logging
This service uses Pythonâ€™s built-in logging module to log events, errors, and key actions throughout the scraping and Q&A pipeline.

ğŸ“¦ Dependencies
fastapi

uvicorn

httpx or aiohttp (async scraping)

beautifulsoup4

sentence-transformers / transformers

openai / langchain / neo4j (as applicable)

All dependencies must be listed in requirements.txt.

ğŸ” Security Recommendations
Add authentication and authorization to endpoints (e.g., OAuth2, API key).

Sanitize and validate all external URLs and inputs.

Monitor usage and set rate limits in production.




